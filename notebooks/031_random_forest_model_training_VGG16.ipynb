{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ab97d9",
   "metadata": {},
   "source": [
    "DATA PREPROCESS + MODEL TRAINING + VGG TO EXTRACT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f29b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668e538",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9aae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7294c7",
   "metadata": {},
   "source": [
    "LOAD VGG16 PRETRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfc4612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg = vgg16(pretrained=True)\n",
    "# Keep only the feature extractor part (remove classifier)\n",
    "vgg_features = nn.Sequential(*list(vgg.children())[:-1])\n",
    "# Set to eval mode\n",
    "vgg_features.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f9dea7",
   "metadata": {},
   "source": [
    "DEFINE PATH FOR ACCESSING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e361fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path of the training dataset (that was already provided to you)\n",
    "import os\n",
    "\n",
    "running_local = True if os.getenv('JUPYTERHUB_USER') is None else False\n",
    "DATASET_PATH = \".\"\n",
    "\n",
    "# Set the location of the dataset\n",
    "if running_local:\n",
    "    # If running on your local machine, the sign_lang_train folder's path should be specified here\n",
    "    local_path = os.path.join('..', '..', 'sign_lang_train')\n",
    "    if os.path.exists(local_path):\n",
    "        DATASET_PATH = local_path\n",
    "else:\n",
    "    # If running on the Jupyter hub, this data folder is already available\n",
    "    # You DO NOT need to upload the data!\n",
    "    DATASET_PATH = \"/data/mlproject22/sign_lang_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from string import ascii_lowercase\n",
    "import torch\n",
    "\n",
    "def read_csv(csv_file):\n",
    "    with open(csv_file, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "    return data\n",
    "\n",
    "class SignLangVGGDataset(Dataset):\n",
    "    \"\"\"Sign language dataset prepared for VGG16 feature extraction\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, class_index_map=None, transform=None):\n",
    "        self.data = read_csv(os.path.join(root_dir, csv_file))\n",
    "        self.root_dir = root_dir\n",
    "        self.class_index_map = class_index_map\n",
    "        self.transform = transform\n",
    "        self.class_names = list(map(str, list(range(10)))) + list(ascii_lowercase)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image_path = os.path.join(self.root_dir, self.data[idx][1])\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize and convert to 3 channels\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = np.stack([image] * 3, axis=0)  # shape: (3, 224, 224)\n",
    "\n",
    "        label = self.class_names.index(self.data[idx][0])\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f98a70",
   "metadata": {},
   "source": [
    "NOW IMPORT THE DATASET CLASS THAT CHANGES THE IMAGE FROM 124 TO 224 PIXELS (APPROPIATE FOR THE VGG16)\n",
    "AND USE IT FOR CREATING THE DATASET ITSELF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50229b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_vgg import SignLangVGGDataset\n",
    "csv_filename = \"labels.csv\"  # This is your file inside sign_lang_train\n",
    "dataset = SignLangVGGDataset(csv_file=csv_filename, root_dir=DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cddccd3",
   "metadata": {},
   "source": [
    "MAKE SURE DATASET IS CORRECTLY CREATED AND THAT THE IMAGE SIZE HAS BEEN CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27a4b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (3, 224, 224)\n",
      "Label: 21\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0]\n",
    "\n",
    "print(\"Image shape:\", sample['image'].shape)  # Should be (3, 224, 224)\n",
    "print(\"Label:\", sample['label'])              # Should be int between 0–35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b551646",
   "metadata": {},
   "source": [
    "SET UP DATA LOADER AND MOVE VGG TO DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a36eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg_features = vgg_features.to(device)\n",
    "vgg_features.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a5b98",
   "metadata": {},
   "source": [
    "EXTRACT FEATURES IN BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d50283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        images = batch['image'].float().to(device)\n",
    "        labels_batch = batch['label']\n",
    "\n",
    "        feats = vgg_features(images)                # (B, 512, 7, 7)\n",
    "        feats = feats.view(feats.size(0), -1)       # Flatten to (B, 25088)\n",
    "\n",
    "        features.append(feats.cpu().numpy())\n",
    "        labels.extend(labels_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce542efa",
   "metadata": {},
   "source": [
    "AFTER FEATURE EXTRACTION, STACK THE FEATURES AND TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13e87cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (9680, 25088)\n",
      "Label vector shape: (9680,)\n",
      "First feature vector: [0.5780331 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = np.concatenate(features, axis=0)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)     # should be (9680, 25088)\n",
    "print(\"Label vector shape:\", y.shape)       # should be (9680,)\n",
    "print(\"First feature vector:\", X[0][:10])   # show first 10 values of first image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc068f9d",
   "metadata": {},
   "source": [
    "NOW IT IS TIME TO TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057064fb",
   "metadata": {},
   "source": [
    "FIRST, SPLIT DATA SO WE ENSURE TO EVALUATE ON UNSEEN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff54b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7938cd98",
   "metadata": {},
   "source": [
    "THEN TRAIN ON TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e624e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008db130",
   "metadata": {},
   "source": [
    "EVALUATE ACCURACY ON TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3853ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6601239669421488\n",
      "\n",
      "Detailed report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.533     0.875     0.662       112\n",
      "           1      1.000     0.045     0.087        22\n",
      "           2      0.500     0.045     0.083        22\n",
      "           3      0.000     0.000     0.000        22\n",
      "           4      0.566     0.875     0.688       112\n",
      "           5      1.000     0.087     0.160        23\n",
      "           6      0.497     0.821     0.620       112\n",
      "           7      0.000     0.000     0.000        22\n",
      "           8      1.000     0.029     0.057        34\n",
      "           9      0.709     0.938     0.808       112\n",
      "          10      0.800     0.182     0.296        22\n",
      "          11      0.841     0.661     0.740        56\n",
      "          12      0.766     0.964     0.854       112\n",
      "          13      0.800     0.118     0.205        34\n",
      "          14      1.000     0.174     0.296        23\n",
      "          15      1.000     0.130     0.231        23\n",
      "          16      0.696     0.920     0.792       112\n",
      "          17      0.000     0.000     0.000        22\n",
      "          18      0.920     0.821     0.868        56\n",
      "          19      0.912     0.929     0.920        56\n",
      "          20      0.000     0.000     0.000        34\n",
      "          21      0.804     0.991     0.888       112\n",
      "          22      0.333     0.091     0.143        22\n",
      "          23      0.500     0.043     0.080        23\n",
      "          24      0.000     0.000     0.000        22\n",
      "          25      0.768     0.973     0.858       112\n",
      "          26      1.000     0.304     0.467        23\n",
      "          27      0.000     0.000     0.000        22\n",
      "          28      0.493     0.661     0.565        56\n",
      "          29      0.000     0.000     0.000        21\n",
      "          30      0.492     0.857     0.625       112\n",
      "          31      0.471     0.143     0.219        56\n",
      "          32      0.000     0.000     0.000        22\n",
      "          33      1.000     0.182     0.308        22\n",
      "          34      0.980     0.893     0.935        56\n",
      "          35      0.644     0.839     0.729       112\n",
      "\n",
      "    accuracy                          0.660      1936\n",
      "   macro avg      0.584     0.405     0.394      1936\n",
      "weighted avg      0.635     0.660     0.588      1936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy:\", acc)\n",
    "\n",
    "print(\"\\nDetailed report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbab22c",
   "metadata": {},
   "source": [
    "EXPORT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c0db1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_vgg16_224x224.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"rf_vgg16_224x224.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b69d4c",
   "metadata": {},
   "source": [
    "MODEL EXPORTED IS 150MB. LETS REDUCE THE NUMBER OF TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72f7000d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=30, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=30, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=30, n_jobs=-1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_30 = RandomForestClassifier(n_estimators=30, n_jobs=-1)\n",
    "clf_30.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53bc5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6136363636363636\n",
      "\n",
      "Detailed report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.458     0.866     0.599       112\n",
      "           1      0.500     0.136     0.214        22\n",
      "           2      0.750     0.136     0.231        22\n",
      "           3      1.000     0.045     0.087        22\n",
      "           4      0.566     0.804     0.664       112\n",
      "           5      0.571     0.174     0.267        23\n",
      "           6      0.494     0.759     0.599       112\n",
      "           7      1.000     0.091     0.167        22\n",
      "           8      0.667     0.059     0.108        34\n",
      "           9      0.590     0.911     0.716       112\n",
      "          10      0.500     0.136     0.214        22\n",
      "          11      0.717     0.679     0.697        56\n",
      "          12      0.732     0.902     0.808       112\n",
      "          13      0.000     0.000     0.000        34\n",
      "          14      1.000     0.174     0.296        23\n",
      "          15      0.333     0.043     0.077        23\n",
      "          16      0.687     0.902     0.780       112\n",
      "          17      0.000     0.000     0.000        22\n",
      "          18      0.810     0.607     0.694        56\n",
      "          19      0.833     0.804     0.818        56\n",
      "          20      0.300     0.088     0.136        34\n",
      "          21      0.797     0.946     0.865       112\n",
      "          22      0.286     0.091     0.138        22\n",
      "          23      0.000     0.000     0.000        23\n",
      "          24      0.000     0.000     0.000        22\n",
      "          25      0.783     0.902     0.838       112\n",
      "          26      0.875     0.304     0.452        23\n",
      "          27      0.000     0.000     0.000        22\n",
      "          28      0.481     0.464     0.473        56\n",
      "          29      0.400     0.095     0.154        21\n",
      "          30      0.477     0.750     0.583       112\n",
      "          31      0.357     0.179     0.238        56\n",
      "          32      0.000     0.000     0.000        22\n",
      "          33      1.000     0.136     0.240        22\n",
      "          34      0.902     0.661     0.763        56\n",
      "          35      0.623     0.812     0.705       112\n",
      "\n",
      "    accuracy                          0.614      1936\n",
      "   macro avg      0.541     0.379     0.378      1936\n",
      "weighted avg      0.589     0.614     0.554      1936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_30.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy:\", acc)\n",
    "\n",
    "print(\"\\nDetailed report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3225fc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_vgg16_224x224_30estimators.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_30, \"rf_vgg16_224x224_30estimators.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c6f4b0",
   "metadata": {},
   "source": [
    "SEEMS THAT THERE IS OBVIOUSLY A PROBLEM WITH THE CLASS IMBALANCE SHOWN IN THE EDA. \n",
    "THE MODEL HAS NOT BEEN ABLE TO LEARN FROM THE FEATURES EXTRACTED AS THE 66% GUESS EFFICIENCY SHOWS\n",
    "\n",
    "LETS TRY TO CHANGE SOME THINGS TO MAKE IT BE BETTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25899cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape: (9680, 512)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=512)  # or 256 if you want smaller\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "print(\"New shape:\", X_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06acb51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=50, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, n_jobs=-1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reduced, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "clf_pca = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "clf_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "868dd017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.5423553719008265\n",
      "\n",
      "Detailed report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.378     0.705     0.492       112\n",
      "           1      0.000     0.000     0.000        22\n",
      "           2      0.000     0.000     0.000        22\n",
      "           3      1.000     0.045     0.087        22\n",
      "           4      0.451     0.786     0.573       112\n",
      "           5      0.000     0.000     0.000        23\n",
      "           6      0.385     0.625     0.476       112\n",
      "           7      1.000     0.091     0.167        22\n",
      "           8      0.250     0.029     0.053        34\n",
      "           9      0.525     0.839     0.646       112\n",
      "          10      0.000     0.000     0.000        22\n",
      "          11      0.647     0.393     0.489        56\n",
      "          12      0.606     0.893     0.722       112\n",
      "          13      0.333     0.059     0.100        34\n",
      "          14      1.000     0.087     0.160        23\n",
      "          15      0.667     0.087     0.154        23\n",
      "          16      0.679     0.848     0.754       112\n",
      "          17      1.000     0.045     0.087        22\n",
      "          18      0.571     0.357     0.440        56\n",
      "          19      0.881     0.661     0.755        56\n",
      "          20      0.000     0.000     0.000        34\n",
      "          21      0.678     0.920     0.780       112\n",
      "          22      0.000     0.000     0.000        22\n",
      "          23      0.500     0.043     0.080        23\n",
      "          24      0.000     0.000     0.000        22\n",
      "          25      0.725     0.893     0.800       112\n",
      "          26      0.750     0.130     0.222        23\n",
      "          27      1.000     0.136     0.240        22\n",
      "          28      0.586     0.304     0.400        56\n",
      "          29      0.500     0.048     0.087        21\n",
      "          30      0.453     0.696     0.549       112\n",
      "          31      0.250     0.107     0.150        56\n",
      "          32      0.000     0.000     0.000        22\n",
      "          33      1.000     0.136     0.240        22\n",
      "          34      0.878     0.643     0.742        56\n",
      "          35      0.525     0.741     0.615       112\n",
      "\n",
      "    accuracy                          0.542      1936\n",
      "   macro avg      0.506     0.315     0.307      1936\n",
      "weighted avg      0.530     0.542     0.477      1936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_pca.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy:\", acc)\n",
    "\n",
    "print(\"\\nDetailed report:\\n\")\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d83c9380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sign_rf_model.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_pca, \"sign_rf_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6065930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
