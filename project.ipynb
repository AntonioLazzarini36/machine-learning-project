{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f0735b",
   "metadata": {},
   "source": [
    "## IMPORT ALL THE NECESSARY LIBRARIES FOR THE PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9daae3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from opencv-python) (1.24.4)\n",
      "Requirement already satisfied: torch in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.19.1-cp38-cp38-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: torch==2.4.1 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch==2.4.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch==2.4.1->torchvision) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\frala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.19.1-cp38-cp38-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 1.0/1.3 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 8.2 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.19.1\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d0b6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, utils, io\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from tqdm import tqdm # For progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e854d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path of the training dataset (that was already provided to you)\n",
    "\n",
    "running_local = True if os.getenv('JUPYTERHUB_USER') is None else False\n",
    "DATASET_PATH = \".\"\n",
    "\n",
    "# Set the location of the dataset\n",
    "if running_local:\n",
    "    # If running on your local machine, the sign_lang_train folder's path should be specified here\n",
    "    local_path = os.path.join('..', 'sign_lang_train')\n",
    "    if os.path.exists(local_path):\n",
    "        DATASET_PATH = local_path\n",
    "else:\n",
    "    # If running on the Jupyter hub, this data folder is already available\n",
    "    # You DO NOT need to upload the data!\n",
    "    DATASET_PATH = \"/data/mlproject22/sign_lang_train\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f306ad",
   "metadata": {},
   "source": [
    "### 1.2 Data Loading using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LETS READ THE CSV FILE AND THE .JPG FILES WITH THE CLASS BUILT IN SRC ###\n",
    "from datasets import SignLangDataset\n",
    "csv_filename = \"labels.csv\"  # This is your file inside sign_lang_train\n",
    "\n",
    "# Create dataset\n",
    "dataset = SignLangDataset(csv_file=csv_filename, root_dir=DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50fa8ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9680"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DID WE READ IT CORRECTLY??? ###\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2339166",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AFTER MAKING SURE THAT THE DATASET IS CORRECTLY UPLOADED ###\n",
    "### SPLIT THE DATASET INTO TRAINING AND VALIDATION SETS ###\n",
    "# 80/20 split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa13cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE THE DATALOADERS TO LOAD THE DATA IN BATCHES OR TO SHUFFLE IT IF NEEDED ###\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb58d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7744/7744 [00:09<00:00, 853.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1936/1936 [00:02<00:00, 849.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (7744, 524288)\n",
      "Shape of y_train: (7744,)\n",
      "Shape of X_val: (1936, 524288)\n",
      "Shape of y_val: (1936,)\n"
     ]
    }
   ],
   "source": [
    "### RANDOM FOREST MODEL IS OUR SECOND OPTION ###\n",
    "\n",
    "# 1. Feature extraction transform\n",
    "class FlattenImageTransform:\n",
    "    def __init__(self, target_size=(64, 64)):\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image'] # Shape (1, H, W)\n",
    "        label = sample['label']\n",
    "\n",
    "        # Convert torch tensor to numpy array if necessary for cv2\n",
    "        # Your __getitem__ already returns numpy, so this might not be strictly needed,\n",
    "        # but it's good practice if you introduce other torch transforms later.\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.squeeze(0).numpy() # Remove channel dim, convert to numpy (H, W)\n",
    "\n",
    "        # Resize the image (important for consistent feature vector length)\n",
    "        # Interpolation method for resizing grayscale images\n",
    "        image_resized = cv2.resize(image, self.target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Flatten the image into a 1D feature vector\n",
    "        features = image_resized.flatten() # Shape (target_size[0] * target_size[1],)\n",
    "\n",
    "        return {'features': features, 'label': label}\n",
    "    \n",
    "# For Flattened Pixels:\n",
    "transform_for_rf = FlattenImageTransform(target_size=(64, 64))\n",
    "\n",
    "# Or for HOG:\n",
    "# transform_for_rf = HOGFeatureTransform(target_size=(64, 64))\n",
    "\n",
    "\n",
    "# Re-create the dataset instances with the new transform\n",
    "# NOTE: Your current SignLangDataset doesn't directly take `transform` in __getitem__\n",
    "# You commented out `if self.transform: sample = self.transform(sample)`\n",
    "# You need to uncomment/implement that or apply the transform manually as shown below.\n",
    "\n",
    "# Let's assume you'll apply it manually by processing the data loaders:\n",
    "\n",
    "# --- Manually apply transform and collect features/labels ---\n",
    "X_train_features = []\n",
    "y_train_labels = []\n",
    "X_val_features = []\n",
    "y_val_labels = []\n",
    "\n",
    "print(\"Extracting features from training data...\")\n",
    "for i, sample in enumerate(tqdm(train_dataset)):\n",
    "    processed_sample = transform_for_rf(sample)\n",
    "    X_train_features.append(processed_sample['features'])\n",
    "    y_train_labels.append(processed_sample['label'])\n",
    "\n",
    "print(\"Extracting features from validation data...\")\n",
    "for i, sample in enumerate(tqdm(val_dataset)):\n",
    "    processed_sample = transform_for_rf(sample)\n",
    "    X_val_features.append(processed_sample['features'])\n",
    "    y_val_labels.append(processed_sample['label'])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train_features)\n",
    "y_train = np.array(y_train_labels)\n",
    "X_val = np.array(X_val_features)\n",
    "y_val = np.array(y_val_labels)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_val: {X_val.shape}\")\n",
    "print(f\"Shape of y_val: {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b245ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest Classifier...\n",
      "Training complete.\n",
      "\n",
      "Evaluating the model on the validation set...\n",
      "Validation Accuracy: 0.7237\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       128\n",
      "           1       1.00      0.21      0.35        28\n",
      "           2       0.50      0.04      0.07        25\n",
      "           3       0.80      0.21      0.33        19\n",
      "           4       0.63      0.89      0.74       117\n",
      "           5       0.62      0.50      0.55        16\n",
      "           6       0.59      0.79      0.67       112\n",
      "           7       0.00      0.00      0.00        20\n",
      "           8       1.00      0.14      0.24        37\n",
      "           9       0.72      0.94      0.81       114\n",
      "           a       0.73      0.38      0.50        21\n",
      "           b       0.90      0.87      0.89        54\n",
      "           c       0.85      0.93      0.89       100\n",
      "           d       0.80      0.36      0.50        33\n",
      "           e       1.00      0.35      0.52        23\n",
      "           f       0.91      0.40      0.56        25\n",
      "           g       0.82      0.99      0.90       112\n",
      "           h       0.57      0.25      0.35        16\n",
      "           i       0.81      0.70      0.75        60\n",
      "           j       0.94      0.97      0.95        65\n",
      "           k       1.00      0.45      0.62        40\n",
      "           l       0.84      0.97      0.90       104\n",
      "           m       0.73      0.27      0.39        30\n",
      "           n       0.64      0.39      0.48        18\n",
      "           o       0.00      0.00      0.00        25\n",
      "           p       0.85      0.94      0.89       106\n",
      "           q       1.00      0.76      0.87        17\n",
      "           r       0.00      0.00      0.00        20\n",
      "           s       0.41      0.91      0.57        35\n",
      "           t       1.00      0.13      0.23        23\n",
      "           u       0.49      0.88      0.63       102\n",
      "           v       0.74      0.27      0.40        62\n",
      "           w       1.00      0.05      0.09        21\n",
      "           x       0.91      0.45      0.61        22\n",
      "           y       0.83      0.86      0.84        57\n",
      "           z       0.68      0.88      0.76       129\n",
      "\n",
      "    accuracy                           0.72      1936\n",
      "   macro avg       0.72      0.53      0.55      1936\n",
      "weighted avg       0.74      0.72      0.68      1936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\frala\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2. Train the Random Forest Classifier\n",
    "print(\"\\nTraining Random Forest Classifier...\")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 uses all available cores\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# 3. Evaluate the model\n",
    "print(\"\\nEvaluating the model on the validation set...\")\n",
    "y_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Optional: Print a more detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "# You'll need the original class names for a clearer report\n",
    "# Assuming your dataset.class_names is available\n",
    "# For example: class_names = list(map(str, list(range(10)))) + list(ascii_lowercase)\n",
    "# from string import ascii_lowercase\n",
    "# full_class_names = list(map(str, list(range(10)))) + list(ascii_lowercase)\n",
    "print(classification_report(y_val, y_pred, target_names=dataset.class_names))\n",
    "\n",
    "# You can also save your model if you wish\n",
    "# import joblib\n",
    "# joblib.dump(rf_classifier, 'random_forest_model.joblib')\n",
    "# print(\"Random Forest model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d29aa074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to random_forest_sign_lang_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# --- Saving the model ---\n",
    "model_filename = 'random_forest_sign_lang_model.joblib'\n",
    "joblib.dump(rf_classifier, model_filename) # Replace rf_model with rf_model_hog or rf_model_deep if you used those\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "# --- Loading the model later (in a new script or session) ---\n",
    "# loaded_rf_model = joblib.load(model_filename)\n",
    "# print(\"Model loaded successfully!\")\n",
    "\n",
    "# --- Example of using the loaded model for prediction (if you load it) ---\n",
    "# new_image_features = ... # Your new image, preprocessed using the SAME feature extraction method\n",
    "# prediction = loaded_rf_model.predict(new_image_features)\n",
    "# predicted_class_name = dataset.class_names[prediction[0]] # Assuming prediction is an array\n",
    "# print(f\"Predicted class for new image: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad64ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
